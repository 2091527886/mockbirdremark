[root@2091527886 MockingBird]# python pre.py /home/nvq/aidatatang_200zh -n 1
Using data from:
    /home/nvq/aidatatang_200zh/aidatatang_200zh/corpus/train
aidatatang_200zh: 100%|█████████████████████| 1/1 [00:21<00:00, 21.05s/speakers]
The dataset consists of 259 utterances, 49073 mel frames, 9783840 audio timesteps (0.17 hours).
Max input length (text chars): 142
Max mel frames length: 452
Max audio timesteps length: 90240
Embedding:   0%|                                | 0/259 [00:00<?, ?utterances/s]
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/nvq/MockingBird/synthesizer/preprocess.py", line 94, in embed_utterance
    encoder.load_model(encoder_model_fpath)
  File "/home/nvq/MockingBird/encoder/inference.py", line 32, in load_model
    _model = SpeakerEncoder(_device, torch.device("cpu"))
  File "/home/nvq/MockingBird/encoder/model.py", line 21, in __init__
    batch_first=True).to(device)
  File "/usr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/usr/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 182, in _apply
    ret = super(RNNBase, self)._apply(fn)
  File "/usr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/usr/lib/python3.10/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: HIP out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.98 GiB total capacity; 0 bytes already allocated; 15.98 GiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_HIP_ALLOC_CONF
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nvq/MockingBird/pre.py", line 76, in <module>
    create_embeddings(synthesizer_root=args.out_dir, n_processes=n_processes_embed, encoder_model_fpath=encoder_model_fpath)    
  File "/home/nvq/MockingBird/synthesizer/preprocess.py", line 120, in create_embeddings
    list(tqdm(job, "Embedding", len(fpaths), unit="utterances"))
  File "/usr/lib/python3.10/site-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/usr/lib/python3.10/multiprocessing/pool.py", line 870, in next
    raise value
RuntimeError: HIP out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.98 GiB total capacity; 0 bytes already allocated; 15.98 GiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_HIP_ALLOC_CONF


import torch   # 能否调用pytorch库

print(torch.cuda.current_device())   # 输出当前设备（我只有一个GPU为0）
print(torch.cuda.device(0))   # <torch.cuda.device object at 0x7fdfb60aa588>
print(torch.cuda.device_count())  # 输出含有的GPU数目
print(torch.cuda.get_device_name(0))  # 输出GPU名称 --比如1080Ti
x = torch.rand(5, 3)
print(x)  # 输出一个5 x 3 的tenor(张量)



